**LSA - Latent Semantic Analysis**

Латентный семантический анализ - это метод обработки информации на естественном языке, 
анализирующий взаимосвязь между коллекцией документов и терминами в них встречающимися, 
сопоставляющий некоторые факторы (тематики) всем документам и терминам.  

В целом ЛСА включает в себя этапы предобработки документов, такие как приведение словоформ к 
нормальной форме, удаление из анализа малозначимых слов (стоп-слов), вычисление весов слов,
например TF-IDF, представление документа в виде вектора, размерность которого соответствует
количеству термов в языке (за вычетом не учитывающихся, редких и стоп-слов). Применительно к
полученному массиву векторов высокой размерности (матрица **A**) выполняется сингулярное разложение 
(SVD - Singular Value Decomposition):

**A = U s Vt**

Таким образом, исходная матрица представляется в виде произведения трёх матриц, две из которых
**U** и **Vt** образуют ортогональный базис, а диагональная матрица **s** содержит значимость
соответствующих факторов в базисе. Значения в матрице **s** сортированы по убыванию, поэтому
сначала идут наиболее значимые факторы. Такое разложение полезно, существенно сократив размерность 
матриц разложения получить хорошее приближение для матрицы **A ~ U s Vt** - предполагается, что
тут матрицы разложения уже "урезаны".

**U** - матрица m x k. Строки матрицы U - это документы, столбцы - концепты (факторы).
**s** - собственные значения концептов.
**Vt** - столбцы это термы, строки концепты.

Обычно число концептов сокращают до 400-600.
Если входной вектор **x** - это высокоразмерный вектор документа, то для получения "концептуального"
вектора документа требуется выполнить:

**z = Vt * x**

Опционально можно также нормировать полученный вектор на "значимость" концептов, разделив каждую
компоненту вектора z на соответствующее значение матрицы s.

Кроме того можно нормировать полученный вектор к единичной длине. Это позволит достичь эквивалентности
между косинусной мерой близости и евклидовой.

Матрица, полученная на ~ 2 млн. документах, выложена тут:
Матрица получена на предвычисленных весах термов для каждого документа (за подробностями к Роману Мальцеву).

Реализация данного подхода внутри класса **LsaDoc** позволяет использовать большие коллекции документов
за счёт использования специальной библиотеки, выполняющей SVD-разложение для разреженных матриц.

Приведён пример вызова методов для получения матрицы Vt на коллекции документов в json-формате 
с предвычисленными весами слов.

Также приведён тестовый пример кластеризации документов при помощи LSA и агломеративной таксономии.
Для работы необходим класс Aggl

**Результаты**

Результаты таксономии и матрица выложены в локальный ресурс

\\10.250.83.233\shareST\TxtCorpus\LSA\



 
